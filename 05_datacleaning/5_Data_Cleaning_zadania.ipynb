{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8B3Tbf6UnH7q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jj4cqcDOLYqN"},"source":["# Data Cleaning\n","\n","Przed uruchomieniem naszych danych przez model ważnym krokiem jest **Eksploracyjna analiza danych** lub EDA. EDA, jak sama nazwa wskazuje, to dogłębna analiza naszych danych. Proces EDA przeplata czyszczenie danych, radzenie sobie z brakującymi wartościami oraz wizualizację danych i ich właściwości statystycznych. Zazwyczaj wszystkie te procesy są wykonywane razem, ale dla potrzeb edukacyjnych rozbijemy je na osobne części.\n","\n","### Prerequisites\n","[flights.txt](https://drive.google.com/file/d/1cVV3TZcxS31fk9JrskaRP1pbOfaoNcwe/view?usp=sharing)\n","(źródło: https://www.kaggle.com/mmetter/flights/data).\n","W większości przypadków dane posiadają dokumentację. **Czytanie dokumentacji danych jest ważne**!!!! Ta konkretna część danych nie ma jednak żadnej dokumentacji - będziemy musieli skorzystać z naszej intuicji oraz nazw kolumn (zmiennych).\n","\n","### Typy danych\n","\n","<table >\n","\t<tbody>\n","\t\t<tr>\n","            <td><b>Typ danych</b></td>\n","            <td><b>Typ danych w Pythonie</b></td>\n","            <td><b>Przykłady</b></td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Dane tekstowe</td>\n","            <td>str</td>\n","\t\t\t<td>Nazwiska, adresy</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Integers</td>\n","            <td>int</td>\n","\t\t\t<td># przedmioty, # osoby</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Floats/Ułamki</td>\n","            <td>float</td>\n","\t\t\t<td>Waluty, odległości</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Binary/Boolean</td>\n","            <td>bool</td>\n","\t\t\t<td>Pytania zamknięte, yes/no</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Data (i czas)</td>\n","            <td>datetime</td>\n","\t\t\t<td>Data wysyłki, czas przyjazdu</td>\n","\t\t</tr>\n","\t\t<tr>\n","\t\t\t<td>Kategorie</td>\n","            <td>category</td>\n","\t\t\t<td>Stany, kolory, płeć</td>\n","\t\t</tr>\n","\t</tbody>\n","</table>"]},{"cell_type":"code","source":["path='sciezka na twoim dysku/komputerze'"],"metadata":{"id":"jxH6Py-e1Qzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OqdQSm72LYqg"},"outputs":[],"source":["import pandas as pd\n","pd.set_option('display.max_columns', None)\n","flights_df = pd.read_csv(\"flights.txt\", sep=\"|\")"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"EKCaICraLYql"},"outputs":[],"source":["flights_df.head()"]},{"cell_type":"markdown","metadata":{"id":"Ep16wLemLYqp"},"source":["Zestaw danych flights jest problematyzny z wielu względów, ale zanim na nie odpowiemy, przyjrzymy się nazwom zmiennych."]},{"cell_type":"markdown","metadata":{"id":"vxcZaN6-LYqs"},"source":["- **TRANSACTIONID**: Unikalny identyfikator\n","\n","- **FLIGHTDATE**: Data lotu. Wygląda na to, że jest zakodowana jako liczba zamiast obiektu daty\n","\n","- **TAILNUM**: Wygląda na to, że w niektórych wierszach zawiera @@ \n","\n","- **ORIGAIRPORTNAME** oraz **DESTAIRPORTNAME**: Wygląda na to, że nazwa miasta i stan są połączone i dołączone przed rzeczywistą nazwą lotniska \n","\n","- **CRSDEPTIME** oraz **DEPTIME**: Wygląda na to, że zawierają niepoprawnie sformatowane czasy. Wydaje się też, że: **CRSDEPTTIME** + **DEPDELAY** = **DEPTIME**\n","\n","- **DEPDELAY**: Opóźnienie wyjazdu w minutach?\n","\n","- **TAXIOUT**: Ile czasu upłynęło od wystartowania silnika do oderwania się od ziemi? Poza tym: **DEPTIME** + **TAXIOUT** = **WHEELSOFF**\n","\n","- **WHEELSOFF**: Czas, w którym koła oderwały się od ziemi\n","\n","- **WHEELSON**: Czas, w którym koła dotknęły ziemi podczas lądowania\n","\n","- **TAXIIN**: Wygląda na liczbę minut od zetknięcia kół z ziemią do „parkowania”\n","\n","- **CRSARRTIME**: Oczekiwany czas przylotu w formacie 24h\n","\n","- **ARRTIME**: Faktyczny czas przylotu \n","\n","- **ARRDELAY**: Różnica pomiędzy **CRSARRTIME** oraz **ARRTIME**\n","\n","- **CRSELAPSEDTIME**: Planowany czas podróży (minuty)\n","\n","- **ACTUALELAPSEDTIME**: Rzeczywisty czas podróży (minuty)\n","\n","- **CANCELLED**: Czy lot został odwołany czy nie. Niektóre wartości logiczne zostały przedstawione jako False, inne jako 0. Podobnie jest z wartościami True i 1.\n","\n","- **DIVERTED**: Czy samolot został przekierowany. Podobne problemy dotyczące True/False jak powyżej?\n","\n","- **DISTANCE**: Odległość (całkowita) przebyta przez samolot, zakodowana jako ciąg znaków z połączonymi z nim „milami” "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Epxt7igLYqv"},"outputs":[],"source":["flights_df"]},{"cell_type":"markdown","metadata":{"id":"uzVzEvaHLYqx"},"source":["Tak więc przechodzenie przez każdą kolumnę identyfikuje problemy, które może mieć zestaw danych. Najpierw zajmijmy się kwestią **odległości**. Wygląda na to, że ma to być zakodowane _całkowite_ (zauważ, że na początku tego wykładu powiedziałem, że odległości mogą być zmiennoprzecinkowe. Dlaczego zmiana zdania?) i mają dopisane 'mile' na końcu numer. Możemy zrobić o wiele więcej rzeczy z danymi liczbowymi niż danymi tekstowymi, które reprezentują liczby, więc najpierw przekonwertujmy to na int.\n","Aalizująć tabelę kolumna po kolumnie dostrzegamy różne problemy, z jakimi musimy się zmierzyć w tym zbiorze danych. Można zacząć od problemu odległości. Wygląda na to, że odległość miała być zakodowana jako integery, ale pojawiają oznaczenia miar. Dane numeryczne pozwalają na o wiele więcej operacji niż dane tekstowe, dlatego należy wyczyścić te wartości tekstowe.\n","\n","<table>\n","    <tr>\n","        <td> </td>\n","        <td><b>OrderID</b></td>\n","        <td><b>Cost</b></td>\n","        <td><b>Quantity</b></td>\n","        <td><b>Address</b></td>\n","    </tr>\n","    <tr>\n","        <td>0</td>\n","        <td>1234</td>\n","        <td>£1000.00</td>\n","        <td>10</td>\n","        <td>123 Fake Street</td>\n","    </tr>\n","    <tr>\n","        <td>1</td>\n","        <td>7890</td>\n","        <td>£35.50</td>\n","        <td>3</td>\n","        <td>789 Real Road</td>\n","    </tr>\n","    \n","</table>\n","W powyższej tabeli widzimy, że koszt powinien być liczbą zmiennoprzecinkową - jednak ma dołączony symbol £. Aby użyć tej kolumny jako float, musimy usunąć £. Jednak zanim to zrobimy, spójrzmy na typy danych kolumn. Odbywa się to poprzez wywołanie atrybutu `.dtypes` w naszej ramce danych. W powyższym przykładzie zwrócilibyśmy:\n","\n","\n","<table>\n","    <tr>\n","        <td>OrderID</td>\n","        <td>int64</td>\n","    </tr>\n","    <tr>\n","        <td>Cost</td>\n","        <td>object</td>\n","    </tr>\n","    <tr>\n","        <td>Quantity</td>\n","        <td>int64</td>\n","    </tr>\n","    <tr>\n","        <td>Address</td>\n","        <td>object</td>\n","    </tr>\n","</table>\n","\n","Możemy również użyć metody `.info()`, która zwraca nam również informacje o wartościach null w każdej kolumnie (wkrótce omówimy, jak radzić sobie z wartościami null/brakującymi wartościami)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvIMhtpALYq0"},"outputs":[],"source":["## Znajdź typy obiektów dla każdej kolumny za pomocą .dtypes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whRww4YGLYq2"},"outputs":[],"source":["## Znajdź typy obiektów i liczbę wartości null za pomocą .info()\n"]},{"cell_type":"markdown","metadata":{"id":"-vZ1UrNULYq4"},"source":["If we were to sum our above <b>cost</b> column (`sales['cost'].sum()`), something akin to the following would be returned:\n","```£1000.00£35.50£46.10£76.35```...\n","\n","Obviously this isn't what we want.. we'd rather have all our costs summed.\n","\n","Try the same with the 'DISTANCE' column with our flights data\n","\n","Gdybyśmy mieli zsumować powyższą kolumnę <b>cost</b> (`sales['cost'].sum()`), zwrócone zostałoby coś podobnego do następującego ciągu:\n","```£1000,00£35.50£46.10£76.35```...\n","\n","Oczywiście nie o to nam chodzi... wolimy zsumować wszystkie nasze koszty.\n","\n","Powtórz ten krok z kolumną „DISTANCE” z danymi dotyczącymi lotów"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1AF1FnNLYq9"},"outputs":[],"source":["## Zsumuj pierwsze 10 wystąpień kolumny „DISTANCE” w danych lotów.\n","# Bądź świadomy tego, gdzie używasz slicingu :). Jaka jest techniczna różnica między slicingiem przed .sum() i po?\n"]},{"cell_type":"markdown","metadata":{"id":"XJgUwSoTLYq_"},"source":["Aby rozwiązać problem z naszymi danymi sprzedaży, musimy zrobić dwie rzeczy:\n","1. Usuąć „£”\n","2. Zamienić kolumnę na zmiennoprzecinkowy typ danych\n","\n","Odbywałoby się to w następujący sposób:\n","```python\n","sales['cost'] = sales['cost'].str.strip('£')\n","sales['cost'] = sales['cost'].astype('float64')\n","```\n","\n","Uzbrojeni w tę wiedzę, zamieńmy kolumnę odległości na int!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sTpHRvELYrA"},"outputs":[],"source":["## Usuń „mile” z ramki danych\n","flights_df[\"DISTANCE\"] = \n","## Zamień kolumnę na typ int64\n","\n","## Sprawdź, czy kolumna została pomyślnie przekonwertowana na int"]},{"cell_type":"markdown","metadata":{"id":"9IpyIhvFLYrB"},"source":["Świetnie! W ten sposób możemy przekonwertować nieuporządkowane dane tekstowe na liczby. Przyjrzyjmy się teraz konwersji danych na wartości kategoryczne.\n","\n","W naszym zbiorze danych mamy wiele kolumn, które mogą być kategoryczne. Czy potrafisz określić, które to są?\n","<br>\n","<details>\n","    <summary><b>></b> Categorical variables (click to reveal)</summary>\n","    <ul>\n","        <li>AIRLINECODE</li>\n","        <li>AIRLINENAME</li>\n","        <li>ORIGINAIRPORTCODE</li>\n","        <li>ORIGAIRPORTNAME</li>\n","        <li>ORIGINCITYNAME</li>\n","        <li>ORIGINSTATE</li>\n","        <li>ORIGINSTATENAME</li>\n","        <li>DESTAIRPORTCODE</li>\n","        <li>DESTAIRPORTNAME</li>\n","        <li>DESTCITYNAME</li>\n","        <li>DESTSTATE</li>\n","        <li>DESTSTATENAME</li>\n","    </ul>\n","</details>\n","\n","Używając metody `.describe()` możemy dostać więcej informacji o konkretnej kolumnie. Użyjmy jako przykładu `AIRLINECODE`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3g-_O2p_LYrC"},"outputs":[],"source":["flights_df['DISTANCE'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWnfRuo3LYrD"},"outputs":[],"source":["flights_df['AIRLINECODE']"]},{"cell_type":"markdown","metadata":{"id":"O3tMZgVkLYrE"},"source":["Gdy uruchomimy `.describe()` nad tą zmienną, otrzymujemy kilka (średnio) użytecznych statystyk. Widzimy jednak, że typ danych tej kolumny został zinterpretowany jako `object`. Z tabeli typów danych, którą wprowadziliśmy wcześniej, widzimy, że istnieje obsługa kategorii. Przekształćmy to w kategorię i zobaczmy różnicę w stosunku do metody opisu."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"9c-qVBAxLYrF"},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n","flights_df['AIRLINECODE']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RbmqOUALYrG"},"outputs":[],"source":["flights_df['AIRLINECODE'].describe()"]},{"cell_type":"markdown","metadata":{"id":"VHPG7fHoLYrG"},"source":["Tak naprawdę brak widocznej różnicy po użyciu metody `.describe()` (co dziwne, wciąż zwraca dtype object)! Użyjemy metody `.info()`, aby sprawdzić nasze zużycie pamięci"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"USF0oZ8yLYrH"},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('object')\n","flights_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"B2Z09NL_LYrI"},"outputs":[],"source":["flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n","flights_df.info()"]},{"cell_type":"markdown","metadata":{"id":"hHR0mRfDLYrL"},"source":["Widzimy, że nasze zużycie pamięci spadło o około 8 MB po przekształceniu tej jednej kolumny w kategorię! Ok, tak, wprawdzie nie jest to wielka sprawa przy pracy z danymi o tym rozmiarze, ale pamiętaj, że oszczędność pamięci pochodzi tylko z jednej z wielu kategorycznych kolumn, które mamy.\n","\n","Więc dlaczego tak jest? Cóż, pod maską Pandas reprezentują kategorie jako typy całkowite. W rzeczywistości coś, na co możesz natknąć się podczas pracy z innymi zestawami danych, to jawne wyświetlanie kolumny kategorii zakodowanej jako liczby całkowite. Zmodyfikujmy naszą ramkę danych, aby zobaczyć, co się stanie dalej."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8GVmfMNULYrN"},"outputs":[],"source":["flights_df['AIRLINECODE_ASINT'] = flights_df['AIRLINECODE'].cat.codes.astype('int8')\n","flights_df['AIRLINECODE_ASINT']"]},{"cell_type":"markdown","metadata":{"id":"MtBq3U1cLYrP"},"source":["Kiedy uruchamiamy `.describe()` możemy zobaczyć zwrócone statystyki, które nie mają sensu dla naszej kolumny:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u59__uX1LYrP"},"outputs":[],"source":["flights_df['AIRLINECODE_ASINT'].describe()"]},{"cell_type":"markdown","metadata":{"id":"95Cenx8OLYrQ"},"source":["Nie ma sensu, aby kolumna kategoryczna miała średnią lub jakiekolwiek inne właściwości statystyczne."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QelJMS3LYrQ"},"outputs":[],"source":["flights_df = flights_df.drop('AIRLINECODE_ASINT', 1)"]},{"cell_type":"markdown","metadata":{"id":"2HMVBclnLYrR"},"source":["Jakie typy danych (numeryczne, datetime, tekst lub kategoryczne) przypisałbyś następującym danym?:\n","\n","- Opis przedmiotu\n","- Roczny dochód\n","- Rozmiar odzieży\n","- Czas przylotu samolotu\n","- Urodziny\n","- Smaki koktajli mlecznych w McDonalds\n","- Pierwsza połowa kodu pocztowego\n","- Pełny kod pocztowy\n","- Czas potrzebny biegaczom na ukończenie 5K"]},{"cell_type":"markdown","metadata":{"id":"DHVs9NzqLYrR"},"source":["## Zduplikowane wartości\n","\n","Innym częstym problemem, z którym możemy się spotkać, są **zduplikowane wartości**. Jak sama nazwa wskazuje, dzieje się tak, gdy te same wartości powtarzają się w wielu wierszach lub kolumnach:\n","<table>\n","    <tr>\n","        <td><b>first_name</b></td>\n","        <td><b>last_name</b></td>\n","        <td><b>address</b></td>\n","        <td><b>age</b></td>\n","        <td><b>income</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>123 Real Street</td>\n","        <td>25</td>\n","        <td>£28000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>31</td>\n","        <td>£32000</td>\n","    </tr>\n","</table>\n","\n","W powyższym przykładzie widzimy, że Jane Smith ma dwa wpisy bezpośrednio zduplikowane. Jednak w niektórych przypadkach możemy zobaczyć bardzo podobne wpisy:\n","\n","<table>\n","    <tr>\n","        <td><b>first_name</b></td>\n","        <td><b>last_name</b></td>\n","        <td><b>address</b></td>\n","        <td><b>age</b></td>\n","        <td><b>income</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>123 Real Street</td>\n","        <td>25</td>\n","        <td>£28000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td><b>28</b></td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>29</td>\n","        <td>£32000</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>Smith</td>\n","        <td>789 Fake Road</td>\n","        <td>31</td>\n","        <td>£32000</td>\n","    </tr>\n","</table>\n","\n","(Różnica wieku między obiema Jane Smith). Ten rodzaj duplikatu błędu jest najprawdopodobniej spowodowany problemem z wprowadzaniem danych lub ponownym przesłaniem dowolnego formularza złożonego przez Jane – który został wprowadzony do bazy danych bez usuwania jej starego wpisu.\n","\n","Najczęściej jednak duplikaty danych wynikają z błędów/wzorców projektowych w potokach danych lub najczęściej z łączenia baz danych i konsolidacji danych z różnych zestawów danych/baz danych, które mogą zachować zduplikowane wartości.\n","\n","Pandas udostępnia nam metodę [`.duplicated()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html). Użyjmy tego w naszej ramce danych, aby zobaczyć, co zwraca"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fslvxoC7LYrS"},"outputs":[],"source":["flights_df.duplicated()"]},{"cell_type":"markdown","metadata":{"id":"qm1kK2YaLYrU"},"source":["Zauważ, że możemy użyć `.sum()` do wartości logicznych. Zasadniczo False są interpretowane jako 0, a True jako 1. Tak więc sumując ramkę danych, możemy uzyskać całkowitą liczbę zduplikowanych wartości!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XJBdjnnLYrU"},"outputs":[],"source":["flights_df.duplicated().sum()"]},{"cell_type":"markdown","metadata":{"id":"DfU3KHMXLYrV"},"source":["Brak duplikatów to dobry wynik, ale nie dajmy się zwieść. Przypomnijmy sobie duplikat Jane Smith powyżej. Zduplikowana metoda nie zwróciłaby wartości true, ponieważ cały wiersz nie był dokładnym duplikatem. Dlatego możemy w metodzie `.duplicated()` skorzystać z dwóch argumentów: `subset` i `keep`. Dla argumentu subset podaj listę nazw kolumn, w których chcemy sprawdzić duplikaty, a w argumencie keep podaj  1 z 3 wartości: „pierwsza”, „ostatnia” lub „Fałsz”. Z dokumentacji wiemy, że:\n","- `first` : Oznacz duplikaty jako True z wyjątkiem pierwszego wystąpienia.\n","- `last` : Zaznacz duplikaty jako True z wyjątkiem ostatniego wystąpienia.\n","- `False` : Oznacz wszystkie duplikaty jako True.\n","\n","W wielu przypadkach wybranie podzbioru jest bardziej intuicyjne niż naukowe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DiIyZOlwLYrV"},"outputs":[],"source":["## Znajdź duplikaty w ramce danych lotów w następujących kolumnach, ustaw keep = False:\n"," # \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"\n"," # Przypisz to zmiennej 'duplicates'\n"," # Czy wybrałam dobre klolumny? Postąpiłbyś inaczej?\n","\n","    \n","# Używając df[duplikaty], zwracane są punkty danych, w których istnieją duplikaty.\n","## Zwróć duplikaty dla ramki danych lotów\n"]},{"cell_type":"markdown","metadata":{"id":"2hzEsurbLYrW"},"source":["Jako drugorzędną obserwację widzimy, że „TALINUM” również przyjmuje wartość „UNKNOWN” dla brakujących wartości. Zanotujemy to, abyśmy mogli zająć się tym później.\n","\n","Aby posortować naszą ramkę danych, możemy użyć metody [`.sort_values()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html). Przeczytaj dokumentację i użyj tej metody, aby posortować ramkę danych według nazwy kolumny, która Twoim zdaniem jest odpowiednia (taka, która pozwala łatwo zweryfikować, czy zwrócone wpisy są faktycznymi duplikatami)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnqXT_zULYrX"},"outputs":[],"source":["## Posortuj zduplikowane wartości według odpowiedniego indeksu\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"t0y9FfuLLYrY"},"outputs":[],"source":["flights_df[\"TAILNUM\"].isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"ioHBRmk8LYrZ"},"source":["### Radzenie sobie z duplikatami\n","\n","Mamy dwie opcje:\n","1. Uśrednienie wartości, tam gdzie to możliwe\n","2. Usunięcie jednego z duplikatów (lub wielu, tak by pozostał pojedynczy wiersz)\n","\n","\n","##### Uśrednianie\n","\n","Uśrednianie po zduplikowanych wartościach można tak naprawdę wykonać tylko na typach danych, które mają sens. W powyższej tabeli pierwsze dwa wpisy mają prawidłowe czasy, które możemy uśrednić. Ogólnie rzecz biorąc, sposób, w jaki uśredniamy, to grupowanie według odpowiednich kolumn (poprzez `.groupby()`) i łączenie tego z funkcją `.agg()`. W tym przypadku chcemy pogrupować wg kolumn w podzbiorze poza kolumnami, które nas interesują (np. wg. czasu). Naszym argumentem do `.agg()` jest słownik z parami klucz-wartość nazw kolumn i funkcją agregacji, którą chcemy nad nimi zastosować (np. suma, różnica, średnia itp.)."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"tags":[],"id":"tRu5jXOwLYrc"},"outputs":[],"source":["summaries = {\"CRSARRTIME\": \"mean\", \"ARRTIME\": \"mean\", \"ARRDELAY\": \"mean\", \"CRSELAPSEDTIME\": \"mean\", \"ACTUALELAPSEDTIME\": \"mean\"}\n","\n","grouped_duplicates = flights_df[duplicates].groupby([\"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\"])\n","grouped_duplicates_min_transactionid = grouped_duplicates[\"TRANSACTIONID\"].min().reset_index()\n","\n","f_df_duplicates = pd.merge(\n","    grouped_duplicates_min_transactionid,\n","    grouped_duplicates.agg(summaries).reset_index(),\n","    how=\"inner\"\n",").sort_values(\"TRANSACTIONID\")\n","\n","f_df_duplicates\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"nEWgXqT-ri_O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AEEhirqLYrd"},"outputs":[],"source":["# Dlaczego w polu TRANSACTIONID jest teraz tak wiele nowych NaN?\n","## Jak się ich pozbyć?\n","\n","\n","## Ponownie zakoduj TRANSACTIONID do int64\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"Njgc4uqVLYrh"},"outputs":[],"source":["# Metoda .update() pozwala nam aktualizować rekordy w jednej ramce danych na podstawie wartości w innej\n","# Potrzebny jest pewien sposób \"powiązania\" rekordów do nadpisania/aktualizacji, jeśli nie chcemy używać domyślnego indeksu ramki danych\n","## Tak więc, używając metody .set_index(), ustaw ramkom flight_df i f_df_duplicates nowy indeks na unikalny klucz indentifera, który obaj współdzielą\n","\n","\n","# Teraz możemy zaktualizować ramkę flight_df o nową ramkę danych\n","\n","## I na koniec możemy opcjonalnie zresetować indeks, aby uzyskać domyślne indeksowanie ramki danych\n"]},{"cell_type":"code","source":["flights_df.head(2)"],"metadata":{"id":"_NF3Rpuos1tn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ti9zul4uLYri"},"outputs":[],"source":["flights_df[flights_df[\"TRANSACTIONID\"]==1974100]"]},{"cell_type":"markdown","metadata":{"id":"mhE7iHqPLYrj"},"source":["##### Usuwanie duplikatów\n","\n","Jeśli chodzi o usuwanie duplikatów, Pandas udostępnia nam metodę `.drop_duplicates()`, która przyjmuje trzy argumenty:\n","1. `subset`\n","2. `keep`\n","3. `inplace` - wartość boolean, czy chcemy nadpisać ramkę czy nie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWTWGoZmLYrj"},"outputs":[],"source":["subset = [\"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"]\n","## Używając inplace = True, usuń duplikaty. Zastanów się, jaką wartość powinniśmy ustawić argumentowi keep\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"b2E4w_2nLYrk"},"outputs":[],"source":["flights_df[duplicates].tail()"]},{"cell_type":"markdown","metadata":{"id":"7b0dzVwRLYrl"},"source":["## Dane kategoryczne\n","\n","Wspomnieliśmy już o danych kategorycznych wcześniej, ale tutaj bardziej szczegółowo zdefiniujemy to pojęcie. Zmienne danych kategorycznych przyjmują swoją wartość z predefiniowanego zestawu kategorii. Widzieliśmy powyższy przykład z kodami AIRLINE.\n","\n","Czy poniższe zmienne są kategoryczne?\n","- TAILNUM\n","- FLIGHTNUM\n","- ORIGINAIRPORTCODE\n","- ORIGAIRPORTNAME\n","- CANCELLED\n","\n","A kolumny w poniższej tabeli?\n","\n","<table>\n","    <tr>\n","        <td><b>First Name</b></td>\n","        <td><b>Last Name</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Address</b></td>\n","        <td><b>District Postcode</b></td>\n","        <td><b>Full Postcode</b></td>\n","        <td><b>Married</b><td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>Doe</td>\n","        <td>31</td>\n","        <td>123 Fake Street, Realtown</td>\n","        <td>RT1</td>\n","        <td>RT1 3NV</td>\n","        <td>True</td>\n","    </tr>\n","    <tr>\n","        <td>Diane</td>\n","        <td>Smith</td>\n","        <td>31</td>\n","        <td>42 World Road, Realtown</td>\n","        <td>RT2</td>\n","        <td>RT2 7XU</td>\n","        <td>False</td>\n","    </tr>\n","    <tr>\n","        <td>Kate</td>\n","        <td>Doe</td>\n","        <td>29</td>\n","        <td>123 Fake Street, Realtown</td>\n","        <td>RT1</td>\n","        <td>RT1 3NV</td>\n","        <td>False</td>\n","    </tr>\n","    <tr>\n","        <td>Charlie</td>\n","        <td>Doe</td>\n","        <td>33</td>\n","        <td>789 Real Road, Fakecity</td>\n","        <td>FC2</td>\n","        <td>FC2 9ER</td>\n","        <td>True</td>        \n","    </tr>    \n","</table>\n","Dane kategoryczne mogą przyjmować tylko jedną ze skończonego zestawu wartości i nie jest możliwe, aby wykroczyły poza te uprzednio zdefiniowane kategorie. Jednak podczas procesu zbierania danych może wystąpić szum w naszych danych (np. jeśli nasze dane kategoryczne zostały zebrane za pomocą okienka tekstowego do wprowadzania dowolnej treści).\n","\n","\n","Istnieje kilka sposobów radzenia sobie z niespójnymi kategoriami:\n","1. Usuwanie danych\n","2. Zmiana mapowania kategorii\n","3. Wnioskowanie kategorii\n","\n","### Usuwanie danych\n","\n","\n","Przyjrzyjmy się kolumnie `ORIGINSTATENAME`. Usunięcie danych jest wymagane, gdy mamy wartość, która w naszym wpisie nie znajduje się (koncepcyjnie) we wstępnie zdefiniowanym zestawie kategorii. Zaczniemy od zwrócenia wszystkich unikalnych wartości w zmiennej."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW8mXOLhLYrl"},"outputs":[],"source":["## skonstruuj zbiór unikalnych wartości w ORIGINSTATENAME\n","\n","states"]},{"cell_type":"markdown","metadata":{"id":"vuKmhBJDLYrm"},"source":["Załóżmy teraz, że otrzymaliśmy kilka nowych wpisów, których nazwy stanów nie występują w tym predefiniowanym zestawie kategorii (na przykład „Fakestate”)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJKExsdqLYrm"},"outputs":[],"source":["## używając metody .at() lub .iat() na flight_df, zmodyfikuj jeden z wierszy\n","## w naszej tabeli, aby mieć ORIGINSTATENAME jako Fakestate\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emj6CK9iLYrm"},"outputs":[],"source":["# Wyświetl unikalne wpisy w ORIGINSTATENAME w naszej zmodyfikowanej ramce danych\n","\n","# LUB set(flights_df[\"ORIGINSTATENAME\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8XQau4l5LYrn"},"outputs":[],"source":["## Korzystając z operacji set, znajdź różnicę między stanami początkowymi w naszej ramce danych a naszą predefiniowaną listą\n","\n","inconsistent_categories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LRnimYGLYrn"},"outputs":[],"source":["# Metoda .isin zwraca wszystkie wiersze z ramki danych, w których został spełniony p[rzekazany warunek]\n","\n","flights_df[inconsistent_rows]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6e7KsZWLYro"},"outputs":[],"source":["# Sprytna sztuczka, której możemy użyć do usunięcia wierszy\n","# Jak myślisz, co oznacza ~?\n"]},{"cell_type":"code","source":["set(flights_df['ORIGINSTATENAME'])"],"metadata":{"id":"bS51Zn6hvNxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eEH_Q-kTvNv-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UhfXnORSLYro"},"source":["### Zmiana mapowania kategorii\n","\n","To, co widzieliśmy powyżej, to dane, których nie było w predefiniowanym zestawie kategorii. Jednak możemy również natknąć się na inny rodzaj problemów z danymi kategorycznymi, które lepiej rozwiązywać poprzez ponowne mapowanie kategorii niż usuwanie danych. Odpowiednie miejsca do wykonania tego ponownego mapowania to:\n","1. **Niespójność wartości**: „żonaty”, „niezamężna”, „stanu wolnego”, „ożeniony” <br>\n"," 1. Uważaj też na końcowe białe znaki!\n","2. **Konwertowanie danych na kategorie lub zbyt wiele kategorii**: Załóżmy, że w naszej ramce danych mamy kolumnę dochodu gospodarstwa domowego.\n"," 1. Możemy zmienić ten typ danych na kategoryczny, grupując dochody (np. `0 - 20k`, `20k - 40k`, `40k - 60k`, `60k +` itd.).\n"," 2. Możemy również zredukować to dalej do `low_class`, `middle_class`, `upper_class`\n"," \n","Zajmijmy się nimi w kolejności. W naszej ramce danych lotów kolumny „CANCELLED” i „DIVERTED” przyjmują niespójne wartości. Być może najbezpieczniejszą opcją jest uruchomienie `.value_counts()` na jednej z tych kolumn (`.value_counts()` działa na danych typu `Series`)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CigO83vkLYro"},"outputs":[],"source":["flights_df[\"CANCELLED\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"MtZjIeBlLYrp"},"source":["Świetnie! Widzimy więc, że nasze Fałszywe wartości mogą przyjąć jedną z trzech wartości, a wartości Prawdy też są podobne. Możemy arbitralnie wykorzystać te, których chcemy użyć, posuwając się do przodu. Dla jednoznaczności wybierzmy odpowiednio False i True."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eb4UloJQLYrs"},"outputs":[],"source":["## Skorzystaj z metody replace: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html\n","## Aby zamienić 0, F, 1 and T na odpowiadające wartości w kolumnie CANCELLED\n",")\n","flights_df[\"CANCELLED\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_O-7fSVLYrt"},"outputs":[],"source":["flights_df[\"DIVERTED\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FF16YDZhLYrv"},"outputs":[],"source":["# Możemy alternatywnie użyć słownika, aby \"zredukować\" nasze kategorie.\n","mapping = \n","\n","flights_df[\"DIVERTED\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"GQz1nopdLYrv"},"source":["Jak wspomniano wcześniej, inną sytuacją, w której możemy chcieć ponownie przyporządkować kategorie, jest zmniejszenie liczby wartości w kolumnie. W naszym przypadku załóżmy, że firma lotnicza chciałaby sklasyfikować loty na podstawie długości tras. Tak więc wszystko między 0 a 1000 mil jest `short`, między 1000 a 2500 to `medium`, a 2500+ to `long`.\n","\n","Możemy użyć metody [`.cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) aby zaklasyfikować dane. Musimy podać 3 argumenty:\n","1. `Series`, którą chcemy sklasyfikować\n","2. Bins - liczbę przedziałów\n","3. Labels - etykiety do przypisania przydziałom"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXkSml-3LYrw"},"outputs":[],"source":["import numpy as np\n","\n","bins = [0, 1000, 2500, np.inf]\n","labels = [\"short\", \"medium\", \"long\"]\n","flights_df[\"DISTANCE_CATEGORY\"] = pd.cut(flights_df[\"DISTANCE\"], bins=bins, labels=labels)\n","\n","flights_df[[\"DISTANCE\", \"DISTANCE_CATEGORY\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"spKk3mZkLYrw"},"outputs":[],"source":["flights_df[flights_df[\"DISTANCE_CATEGORY\"] == \"long\"]"]},{"cell_type":"markdown","metadata":{"id":"f9NPqHsLLYrx"},"source":["### Radzenie sobie z danymi datoczasowymi\n","\n","Jednym z typowych problemów, z którymi się spotkasz, jest zajmowanie się datami i godzinami. Czemu? Ponieważ istnieje wiele sposobów formatowania daty, na przykład `DD/MM/RRRR`, `MM/DD/RR`, `X. MIESIĄC ROK` itp. W powyżej ramce danych nasze daty są w rzeczywistości sformatowane jako jedna numer. Pandas dostarcza nam przydatnego pomocnika do konstruowania dat i godzin — to znaczy metodę [`.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html ).\n","\n","Zanim się tym zajmiemy, warto szybko przedstawić, w jaki sposób daty są zwykle przechowywane na komputerach. Zazwyczaj daty są obliczane na podstawie liczby sekund, które upłynęły od **1 stycznia 1970**. Gdy chcemy, znaleźć różnicę w czasie między 3.02.2013 16:00 a 21.01.2013 09:00, program wykonuje swoje operacje na **czasie Epoka/Unix/POSIX** dla tych wartości, a następnie możemy coś zakodować, aby otrzymać wartość z powrotem w wybranym przez nas formacie (np. 13 dni, 7 godzin). Posługując się liczbami:\n","\n","- **3/2/2013 16:00** = 1,359,907,200\n","- **21/1/2013 09:00** = 1,358,758,800\n","\n","Różnica w datach = 1,359,907,200 - 1,358,758,800 = 1,148,400 sekund\n","\n","`format(1148400) = 13 dni, 7 godzin`\n","\n","Przykłady formatowania dat:\n","<table>\n","    <tr>\n","        <td><b>Date</b></td>\n","        <td><b>Datetime format</b></td>\n","    </tr>\n","    <tr>\n","        <td>15th June 2020</td>\n","        <td>%c</td>\n","    </tr>\n","    <tr>\n","        <td>15/06/2020</td>\n","        <td>%d/%m/%Y</td>\n","    </tr>\n","    <tr>\n","        <td>06-15-2020</td>\n","        <td>%m-%d-%Y</td>\n","    </tr>\n","</table>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYdrXAWsLYrx"},"outputs":[],"source":["pd.to_datetime(flights_df[\"FLIGHTDATE\"])"]},{"cell_type":"markdown","metadata":{"id":"AkrrldXzLYry"},"source":["To dlaczego teraz wszystkie daty to 1970-01-01?\n","\n","A to dlatego, że daty są wewnętrznie przechowywane jako sekundy (liczby). Nasza kolumna `FLIGHTDATE` również wyświetla daty lotów w postaci liczb. Tak więc, kiedy uruchamiamy metodę `.to_datetime()`, wszystkie nasze daty są interpretowane jako czas POSIX.\n","\n","Jednym z prostych rozwiązań, aby to naprawić, jest jawne określenie naszego formatu daty i godziny. Biorąc pod uwagę powyższe przykłady, jak myślisz, jaki będzie format daty?\n","One simple solution we can do to fix that is to explicitly specify our datetime?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4IkNWSiLYrz"},"outputs":[],"source":["## Przypisywanie formatu\n","\n","flights_df[\"FLIGHTDATE\"]"]},{"cell_type":"markdown","metadata":{"id":"TVs0VDyQLYr1"},"source":["To rozwiązanie było dość specyficzne dla problemu, który mieliśmy pod ręką. Ale w prawdziwym świecie często można napotkać mieszane formaty dat w jednej ramce danych. Na przykład:\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>Date of Birth</b></td>\n","        <td><b>Age</b></td>\n","    </tr>\n","    <tr>\n","        <td>John</td>\n","        <td>01/07/1995</td>\n","        <td>25</td>\n","    </tr>\n","    <tr>\n","        <td>Jane</td>\n","        <td>20-04-1992</td>\n","        <td>28</td>\n","    </tr>\n","    <tr>\n","        <td>Mark</td>\n","        <td>3rd January 1990</td>\n","        <td>30</td>\n","    </tr>\n","    </table>\n","\n","\n","`.to_datetime()` ponownie przychodzi tutaj na ratunek! W poprzedniej komórce kodu wyraźnie ustawiliśmy format daty (ze względu na nietypowy charakter sposobu przechowywania tej daty w ramce danych) - ale bardziej ogólnie możemy użyć `.to_datetime()`, aby automatycznie wywnioskować format każdej daty z osobna.\n","\n","```python\n","# errors='coerce' means we'll return NA rows for invalid dates\n","df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], infer_datetime_format=True, errors='coerce') \n","```"]},{"cell_type":"markdown","metadata":{"id":"powV2fiNLYr6"},"source":["## Walidacja krzyżowa\n","\n","Co to znaczy sprawdzić integralność naszych danych? Zasadniczo musimy mieć świadomość, że kolumna danych, które widzimy, jest spójna w oparciu o inne kolumny danych. Właśnie to sprawdza się w **walidacji krzyżowej**. Zanim rozszerzę niektóre walidacje krzyżowe w tym zbiorze danych, przedstawię nieco bardziej trywialny przykład, aby pokazać, gdzie niewykonanie takich kontroli może zniekształcić analizę:\n","\n","Poniższa fikcyjna tabela pokazuje wpisy niektórych posiadaczy kredytów studenckich na studia licencjackich (UG) i podyplomowych (PG). Zestaw danych składa się z imienia i nazwiska kredytobiorcy, daty urodzenia (DOB), obecnego wieku (lub wieku zmarłego, jeśli dotyczy, niezależnie od tego, czy zmarli, czy też nie), kwoty ich kredytu UG i PG oraz całkowite kwoty, którą są winni – co powinno być sumą dwóch poprzednich pól. W poniższej tabeli zaznaczono wątpliwe pola kursywą.\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>D.O.B</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Deceased</b></td>\n","        <td><b>U.G Loan (£)</b></td>\n","        <td><b>P.G Loan (£)</b></td>\n","        <td><b>Total Loan (£)</b></td>\n","    </tr>\n","    <tr>\n","        <td>Idaline</td>\n","        <td>1971-04-27</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>24100</td>\n","        <td>11900</td>\n","        <td>36000</td>\n","    </tr>\n","    <tr>\n","        <td>Freddie</td>\n","        <td>1962-12-27</td>\n","        <td>57</td>\n","        <td>F</td>\n","        <td>26600</td>\n","        <td>12600</td>\n","        <td>39200</td>\n","    </tr>\n","    <tr>\n","        <td>Debee</td>\n","        <td>1970-11-19</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>32400</td>\n","        <td>97000</td>\n","        <td><i>42100</i></td>\n","    </tr>\n","    <tr>\n","        <td>Joyann</td>\n","        <td>1957-01-24</td>\n","        <td><i>41</i></td>\n","        <td>T</td>\n","        <td>24400</td>\n","        <td>11500</td>\n","        <td>35900</td>\n","    </tr>\n","    <tr>\n","        <td>Ajay</td>\n","        <td>1960-05-12</td>\n","        <td><i>50</i></td>\n","        <td>F</td>\n","        <td>25500</td>\n","        <td>18800</td>\n","        <td>44300</td>\n","    </tr>\n","    <tr>\n","        <td>Emelia</td>\n","        <td>1957-11-23</td>\n","        <td><i>57</i></td>\n","        <td>T</td>\n","        <td>34000</td>\n","        <td>17500</td>\n","        <td><i>0</i></td>\n","    </tr>\n","            \n","</table>\n","            \n","            ajay, emelia, joyann"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kR0z-XkwLYr6"},"outputs":[],"source":["html_table = \"\"\"\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>D.O.B</b></td>\n","        <td><b>Age</b></td>\n","        <td><b>Deceased</b></td>\n","        <td><b>U.G Loan (£)</b></td>\n","        <td><b>P.G Loan (£)</b></td>\n","        <td><b>Total Loan (£)</b></td>\n","    </tr>\n","    <tr>\n","        <td>Idaline</td>\n","        <td>19710427</td>\n","        <td>50</td>\n","        <td>F</td>\n","        <td>24100</td>\n","        <td>11900</td>\n","        <td>36000</td>\n","    </tr>\n","    <tr>\n","        <td>Freddie</td>\n","        <td>19621227</td>\n","        <td>58</td>\n","        <td>F</td>\n","        <td>26600</td>\n","        <td>12600</td>\n","        <td>39200</td>\n","    </tr>\n","    <tr>\n","        <td>Debee</td>\n","        <td>19701119</td>\n","        <td>49</td>\n","        <td>F</td>\n","        <td>32400</td>\n","        <td>97000</td>\n","        <td><i>42100</i></td>\n","    </tr>\n","    <tr>\n","        <td>Joyann</td>\n","        <td>19570124</td>\n","        <td><i>41</i></td>\n","        <td>T</td>\n","        <td>24400</td>\n","        <td>11500</td>\n","        <td>35900</td>\n","    </tr>\n","    <tr>\n","        <td>Ajay</td>\n","        <td>19600512</td>\n","        <td><i>50</i></td>\n","        <td>F</td>\n","        <td>25500</td>\n","        <td>18800</td>\n","        <td>44300</td>\n","    </tr>\n","    <tr>\n","        <td>Emelia</td>\n","        <td>19571123</td>\n","        <td><i>57</i></td>\n","        <td>T</td>\n","        <td>34000</td>\n","        <td>17500</td>\n","        <td><i>0</i></td>\n","    </tr>\n","            \n","</table>\n","\"\"\"\n","\n","html_df = pd.read_html(html_table, header=0)[0]\n","html_df"]},{"cell_type":"markdown","metadata":{"id":"S-i21GnyLYr-"},"source":["Najpierw popracujmy nad zmienną **Age**. Zgodnie z naszą dokumentacją danych, wiek w komórce powinien odzwierciedlać aktualny wiek kredytobiorców. Wyjątkiem jest sytuacja, gdy kredytobiorca nie żyje, w którym to przypadku wiek powinien zawierać wiek kredytobiorcy w momencie jego śmierci. Najpierw ustalmy, które wiersze łamią ten warunek."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qepP679ELYr_"},"outputs":[],"source":["# najpierw zmieńmy nazwy niektórych kolumn\n","\n","html_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTLV5F1tLYsA"},"outputs":[],"source":["## Zamie nmy 'dob' na obiekt date\n","\n","html_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxfQXSY7LYsA"},"outputs":[],"source":["# Stwórz nową kolumnę „now_date” wypełnioną aktualną datą i godziną\n","html_df[\"now_date\"] \n","\n","## Oblicz różnicę między 'dob' i 'now_date' i zwróć wartość jako lata\n","now_date_dob_difference = \n","now_date_dob_difference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVZohQSNLYsB"},"outputs":[],"source":["# Ta linia zmienia obiekty timedate na rok zmiennoprzecinkowy, który następnie konwertujemy na int\n","now_date_dob_difference = \n","now_date_dob_difference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdbHB3J1LYsC"},"outputs":[],"source":["# Na oko możemy zobaczyć, który wiek nie pasuje do ramki danych, którą pokazaliśmy wcześniej.\n","# Jednak ogólnie zakodujmy to za pomocą logiki pandas.\n","## Zwróć wiersze, w których „now_date_dob_difference” różni się od zmiennej wieku ramki danych\n","html_df[html_df[\"age\"] "]},{"cell_type":"markdown","metadata":{"id":"EptEtKrqLYsC"},"source":["Przyjrzyjmy się, dlaczego powyższe komórki zostały zwrócone. Jak wspomniano wcześniej, jeśli pożyczkobiorca nie żyje, jego wiek powinien to odzwierciedlać. Oznacza to, że wiek Joyann i Emelii jest rzeczywiście prawidłowy. Używając logiki, odfiltrujmy te wiersze, aby zwrócić tylko te wiersze, które mają matematycznie niepoprawny wiek."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"929fTM1BLYsD"},"outputs":[],"source":["## Odfiltruj odpowiednich pożyczkodawców za pomocą logiki (wskazówka: &)\n","incorrect_age_rows \n","incorrect_age_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0TOPBMXLYsD"},"outputs":[],"source":["## Zaktualizuj ramkę danych invalid_age_rows o poprawiony wiek\n","incorrect_age_rows[\"age\"] \n","incorrect_age_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpUiCcuxLYsE"},"outputs":[],"source":["## Teraz zaktualizuj odpowiednie wpisy html_df o kolumnę wieku z ramki danych invalid_age_rows\n","html_df.update(incorrect_age_rows[\"age\"])\n","html_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDKWYHMlLYsE"},"outputs":[],"source":["## Konwertuj wiek z powrotem na int\n","html_df[\"age\"] = \n","## Usuń kolumnę now_date\n","\n","html_df"]},{"cell_type":"markdown","metadata":{"id":"6U-9GkR3LYsE"},"source":["Popracujmy teraz nad kwotami pożyczki. Zwróć wszystkie kolumny, w których `ug_loan` + `pg_loan` nie są równe `total_loan`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kco3vfiQLYsF"},"outputs":[],"source":["## Podzbiór `ug_loan` i `pg_loan` z naszej ramki danych, a następnie sumowanie wzdłuż osi kolumny\n","sum_loans = \n","sum_loans"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY-s7WcPLYsF"},"outputs":[],"source":["## Zwróć wiersze, które mają nieprawidłowe wartości sum\n","incorrect_loan_rows = \n","incorrect_loan_rows"]},{"cell_type":"markdown","metadata":{"id":"rcX8EJxCLYsG"},"source":["### Jak postępować z polami, które nie przeszły walidacji?\n","\n","Tutaj widzimy dwa wiersze, które nie zawierają poprawnych całkowitych kwot kredytu. Analizując każdy z nich z osobna, widzimy, że dane w pierwszym wierszu najprawdopodobniej zawierały niepoprawną wartość `pg_loan` (97 000 GBP w przypadku pożyczki podyplomowej). W drugim, z jakiegoś powodu wartość `total_loan` nie została obliczona. Naiwną strategią może być nadpisanie całkowitych kwot pożyczki sumą `ug_loan` i `pg_loan`. To naprawia typy błędów, w których zwracany jest drugi wiersz. Jednak może istnieć podstawowy problem z powodu pierwszego rzędu. Jeśli zsumujemy tutaj `ug_loan` i `pg_loan`, utworzymy **obserwację odstającą**. W prawdziwym zbiorze danych mogą wystąpić bardzo realne zagrożenia, takie jak te, które mogą narazić na szwank integralność danych – takie problemy mogą łatwo wymykać się spod kontroli, więc upewnij się, że poświęcisz czas na przemyślenie, w jaki sposób Twoje działania wpłyną na Twój dane.\n","\n","Jak wspomniano wcześniej, niektóre aspekty nauki o danych są sztuką – ale jakąkolwiek decyzję heurystyczną podejmiemy, musimy znaleźć dla niej mocne uzasadnienie. W tym konkretnym przypadku zamierzam usunąć wiersze z niepoprawnym `total_loan`, ponieważ ten błąd prawdopodobnie wystąpił z powodu błędu we wprowadzaniu danych przez człowieka. Wiersze z `total_loan = 0` prawdopodobnie wystąpiły z powodu jakiegoś systematycznego błędu - być może z innej bazy danych, w której nie podano sumy total_loan. Biorąc pod uwagę inne weryfikacje, jednym z rozwiązań, które moglibyśmy wybrać, jest zsumowanie dwóch kolumn."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LYmqAwZLYsG"},"outputs":[],"source":["## Zidentyfikuj wiersze, w których total_loan NIE jest równe 0, ale jest niepoprawne\n","\n","print(incorrect_loan_but_not_zero_rows)\n","\n","## Usuń te wiersze\n","html_df = \n","\n","html_df"]},{"cell_type":"code","source":["html_df[(html_df[\"total_loan\"] == 0)]\n"],"metadata":{"id":"gGWk1vQ70JQG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["html_df.drop(index=5, inplace=True)"],"metadata":{"id":"dH61qpbu0kj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFsOwL5fLYsH"},"outputs":[],"source":["# Zakładając, że jesteśmy zadowoleni ze wszystkich innych wpisów w naszych pożyczkobiorcach, możemy bezpośrednio obliczyć i nadpisać total_loan w naszej ramce danych\n","## Zastąp total_loan sumą ug_loan i pg_loan\n","html_df[\"total_loan\"] = \n","html_df"]},{"cell_type":"markdown","metadata":{"id":"OJtBNq4VLYsI"},"source":["## Praca z danymi tekstowymi i typu string\n","\n","Dane tekstowe są oczywiście niezwykle powszechnym rodzajem danych i mogą przybierać różne formy – od tekstu nieustrukturyzowanego po e-maile, nazwiska, numery telefonów itp. Istnieje wiele rodzajów problemów, które możemy napotkać w przypadku danych tekstowych:\n","- Niespójność danych (np. +86 195 448 8582 vs 0086-195-448-8582)\n","- Naruszenia tekstu (np. niedozwolone znaki, błędy w polach wejściowych, literówki w tekście)\n","- Literówki „strukturalne” (np. +86.1954.48858.2)\n","\n","W przykładowej tabeli poniżej widzimy listę osób wraz z ich imionami i numerami telefonów. Jak widać – najprawdopodobniej ze względu na wolne pola tekstowe, nazwiska i numery telefonów zostały wprowadzone w różnych formatach. Naszym zadaniem jest standaryzacja tych pól, aby były spójne w całej ramce danych:\n","\n","<table>\n","    <tr>\n","        <td><b>Name</b></td>\n","        <td><b>Phone Number</b></td>\n","    </tr>\n","    <tr>\n","        <td>Dr Darci Abela</td>\n","        <td>+86-185-338-1819</td>\n","    </tr>\n","    <tr>\n","        <td>Mr Patten St. Queintain</td>\n","        <td>00865872411917</td>\n","    </tr>\n","    <tr>\n","        <td>mr conant burden</td>\n","        <td>0086-289-702-0948</td>\n","    </tr>\n","    <tr>\n","        <td>miss marcia Dutnell</td>\n","        <td>0668</td>\n","    </tr>\n","    <tr>\n","        <td>dr Greggory lurner</td>\n","        <td>+31 778 813 8432</td>\n","    </tr>\n","    <tr>\n","        <td>MS Doe Beavan</td>\n","        <td>+420-731-276-7633</td>\n","    </tr>\n","    <tr>\n","        <td>Tamarah Delgado</td>\n","        <td>+868431029051</td>\n","    </tr>\n","    <tr>\n","        <td>Miss Arlee daborne</td>\n","        <td>+33-307-220-2746</td>\n","    </tr>\n","    <tr>\n","        <td>Ly b. Grima</td>\n","        <td>+238-863-946-4232</td>\n","    </tr>\n","</table>\n","\n","Użyjemy małego sztucznie stworzonego zbioru danych w csv w tym celu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"komt-G9sLYsI"},"outputs":[],"source":["# np = names_phones\n","np_df = pd.read_csv(f\"{path}mock_names_phones.csv\", header=0, index_col=0)\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"uC2JRqb8LYsJ"},"source":["Ok - dla tego dataframe są 4 zadania:\n","1. Utwórz kolumnę title, która zawiera tytuł każdej osoby (np. Pani, Panna itp.). Ta kolumna powinna być znormalizowana i kategoryczna\n","2. Podziel kolumnę name na kolumnę first name i last name. Obie kolumny powinny mieć pierwszą literę imienia z wielkiej litery\n","3. Usuń wiersz `name`\n","4. Standaryzuj numery telefonów w formacie `00XXXXXXXXX`. To znaczy - dwa zera poprzedzone resztą rzeczywistej liczby\n","\n","Zajmijmy się nimi w kolejności"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9s3lKkrWLYsK"},"outputs":[],"source":["# Najpierw chcemy utworzyć nową kolumnę tytułową, która przyjmuje tytuły grzecznościowe w kolumnie imienia\n","# Aby to uzyskać, musimy podzielić name po białym znaku i wziąć pierwszy element z listy podzielonej\n","example_string = \"this string will be split\"\n","print(example_string.split())\n","print(example_string.split()[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lL5XrFl7LYsK"},"outputs":[],"source":["# Aby wykonać operacje na stringach naa kolumnach stringów w pandas, musimy poprzedzić naszą funkcję ciągów znakiem „.str”\n","np_df[\"name\"]\n"]},{"cell_type":"code","source":["def capitalize(txt):\n","  return txt.capitalize()"],"metadata":{"id":"YziGi6jN2CSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjPb9PCyLYsL"},"outputs":[],"source":["## Utwórz i wypełnij kolumnę title.\n","# To zadanie można rozwiązać na kilka różnych sposobów.\n","# Zobacz, ile rozwiązań możesz wymyślić\n","np_df[\"title\"] = \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osnj-IXDLYsM"},"outputs":[],"source":["# Chcemy, aby nasz title był ustandaryzowany i kategoryczny.\n","## Zamień kolumnę na kolumnę kategoryczną i zwróć wszystkie kategorie, które obecnie istnieją w kolumnie\n","np_df[\"title\"] = \n","set(np_df[\"title\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0-m3r5QLYsN"},"outputs":[],"source":["# Widzimy wiele różnych wariantów. Wybierzmy metodę normalizacji wpisów (np. wielkie litery).\n","## Standaryzuj kolumnę title\n","np_df[\"title\"] = \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9aPw9vjLYsO"},"outputs":[],"source":["## W podobny sposób do powyższego utwórz nową kolumnę na imię i jedną na nazwisko.\n","# Upewnij się, że dla obu nowych kolumn nazwy są pisane małymi literami, z wyjątkiem pierwszej litery, która jest pisana wielką literą\n","np_df[\"first_name\"] = \n","np_df[\"last_name\"] = \n","np_df[\"first_name\"] = \n","np_df[\"last_name\"] = \n","\n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5A0O47XcLYsP"},"outputs":[],"source":["## Usuń kolumnę name\n","\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"ClHI4914LYsP"},"source":["Świetnie! To prowadzi nas do czwartej części zadania - ujednolicenia numeru telefonu i przekonwertowania go na typ danych int. Przypomnij sobie, jak chcemy, aby nasze numery telefonów wyglądały: zacznij od 00, a następnie do reszty numeru."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"-BADJwj1LYsQ"},"outputs":[],"source":["# Zwraca wszystkie (unikalne) numery telefonów, dzięki czemu możemy zobaczyć różne typy problemów jakie nas czekają\n","set(np_df[\"phone number\"])"]},{"cell_type":"markdown","metadata":{"id":"lXoj6f0jLYsQ"},"source":["Ok, więc jakie problemy widzisz?\n","<details>\n","     <summary><b>> Kliknij tutaj, aby zobaczyć problemy</b></summary>\n","     <ul>\n","         <li>Numery zaczynają się różnie – niektóre zaczynają się od `+`, inne od `00`</li>\n","         <li>Niektóre numery mają spacje między grupami liczb, inne są dzielone. Niektóre numery również nie mają „grup”</li>\n","         <li>Niektóre numery zaczynają się od spacji, inne od `+ `, inne od `+`.</li>\n","         <li>Niektóre numery mają tylko cztery liczby</li>\n","     </ul>\n","</details>\n","\n","Istnieje kilka sposobów formatowania tych ciągów do pożądanego wyniku. Tutaj poprowadzę cię przez metodę, w której iterujemy wiersze i stosujemy funkcję, aby ponownie przypisać zmienną. Zacznijmy od stworzenia funkcji pośredniej, która pobiera numer telefonu i manipuluje nim do pożądanego wyniku."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-42OF7zLYsR"},"outputs":[],"source":["def standardise_phone_number(phone_number):\n","    \n","    ## jeśli pierwszym znakiem jest \"+\", usuń go.\n","    if phone_number.startswith(\"+\"):\n","        phone_number = \n","    \n","    ## usuń wszystkie spacje z numeru telefonu\n","    phone_number = \n","\n","    ## usuń myślniki z numeru telefonu\n","    phone_number = \n","    \n","    ## jeśli numer nie zaczyna się od 00, dodaj 00 do początku numeru\n","    \n","    \n","    ## zwróć numer telefonu\n","    return phone_number"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S7Yitmh9LYsR"},"outputs":[],"source":["# Będziemy iterować po wierszach ramki danych i ponownie przypiszemy wiersz do standardowego wariantu\n","for index, row in np_df.iterrows():\n","    \n","    ## Odwołaj się do naszej funkcji standaryzacji na numer telefonu dla bieżącej pętli\n","    row[\"phone number\"] = \n","    \n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-bqj0eTLYsS"},"outputs":[],"source":["# W naszej ramce danych nadal znajdują się nieprawidłowe liczby (tj. te, które pierwotnie miały długość 4)\n","## Zamień wszystkie numery telefonów poniżej 10 cyfr/znaków na pd.NA\n","# Podpowiedź: będzie potrzebna metoda .loc\n","np_df\n","np_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHNZ3iqiLYsS"},"outputs":[],"source":["# Skoncentrujemy się na brakujących danych w następnej części, ale policzmy liczbę wierszy z NA i usuńmy je\n","null_phone_numbers = \n","print(\"Number of null phone numbers:\", null_phone_numbers.sum())\n","\n","# Usuń wiersze, które mają puste numery telefonów\n","np_df = np_df.dropna(subset=[\"phone number\"])\n","np_df"]},{"cell_type":"markdown","metadata":{"id":"fTHEVefALYsT"},"source":["Bardziej skomplikowane manipulacje ciągami znaków można wykonać za pomocą **wyrażeń regularnych**, znanych również jako [regex](https://docs.python.org/3/howto/regex.html). Nie będziemy tutaj przyglądać się wyrażeniu regularnemu, ale ważne jest, aby wiedzieć o jego mocy. Zasadniczo wyrażenie regularne pozwala nam określić reguły dla ciągów, które chcemy dopasować. Ma bardzo szerokie zastosowanie. Oto kilka przykładów:\n","- identyfikuj wiadomości e-mail w zakresach tekstu\n","- sprawdź, czy adres URL ma poprawny format\n","- wyodrębnij tylko cyfry z ciągu tekstowego\n","\n","Kiedy natkniesz się na zadania, które wymagają oczyszczenia danych tekstowych, regex jest narzędziem do tego zadania."]},{"cell_type":"markdown","metadata":{"id":"8ZPP2j-VLYsT"},"source":["## Scalanie danych razem (merging)\n","\n","Czasami znajdziemy dane w różnych plikach, które musimy połączyć w jedną ramkę danych, zanim będziemy mogli jej użyć. Przykładem tego są [dane IMDB](http://www.imdb.com/interfaces#plain) – gdzie, być może ze względu na rozmiar dostępnych danych, twórcy postanowili podzielić cały zbiór danych na wiele osobnych plików. Przyjrzyjmy się szybko, jak możemy połączyć dane z tych wielu plików.\n","\n","Źródło: \n","IMDb\n","(http://www.imdb.com).\n","\n","Pliki do pobrania i scalenia to:\n","- tytuł.akas.tsv.gz\n","- tytuł.podstawy.tsv.gz\n","- tytuł.oceny.tsv.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vc6VBzZJLYsT"},"outputs":[],"source":["# URUCHOM TĘ KOMÓRKĘ TYLKO JEŚLI CHCESZ PONOWNIE POBRAĆ CAŁE DANE\n","import requests\n","import gzip\n","import pandas as pd\n","import pickle\n","import os\n","\n","DATA_FOLDER = \"DATA\" # TODO: najpierw ten folder trzeba utworzyc\n","DOWNLOAD_URL = \"https://datasets.imdbws.com/\"\n","files_to_download = [\"title.ratings.tsv.gz\", \"title.akas.tsv.gz\", \"title.basics.tsv.gz\"]\n","\n","\n","for file_string in files_to_download:\n","    # pobierz plik tsv.gz\n","    # plik jest obiektem request\n","    print(\"Getting request for file:\", file_string)\n","    df = pd.read_csv(DOWNLOAD_URL + file_string, sep=\"\\t\", compression=\"gzip\")\n","    df = df.iloc[-10000:]\n","    print(df.shape)\n","    pickle.dump(df, open(os.path.join(DATA_FOLDER, file_string.replace(\".tsv.gz\", \".df\")), \"wb\"))\n","    print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPVse_kYLYsU"},"outputs":[],"source":["ratings_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.ratings.df\"), \"rb\"))\n","films_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.akas.df\"), \"rb\"))\n","basics_df = pickle.load(open(os.path.join(DATA_FOLDER, \"title.basics.df\"), \"rb\"))"]},{"cell_type":"markdown","metadata":{"id":"xSD5qFqrLYsU"},"source":["### Łączenie wielu ramek danych\n","\n","Podobnie jak w SQL, chcemy wykonać jakiś rodzaj [`.join()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) lub [ `.merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge) przez ramki danych, które obecnie posiadamy. Wymaga to ustawienia unikalnego identyfikatora/klucza podstawowego jako indeksu ramek danych. Pamiętaj o dwóch głównych typach złączeń,  **inner** i **lefyt**. Jak myślisz, które podejście będzie bardziej poprawne w tym przypadku?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZX6IVU_LYsV"},"outputs":[],"source":["## zmodyfikuj indeksy ratings_df, basics_df i movies_df, aby wszystkie miały wspólny indeks\n","ratings_df = \n","basics_df = \n","films_df = \n","films_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aNVfICALYsV"},"outputs":[],"source":["## Wykonaj join lub merge z basics_df i ratings_df za pomocą movies_df\n","df = \n","df"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"hnxwaHdwgmuJ"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}